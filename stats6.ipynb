{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f11b7c18-9936-43e5-a8bc-d3b20ecf501d",
   "metadata": {},
   "source": [
    "1\n",
    "\n",
    "Both t-tests and z-tests are statistical tests used to assess hypotheses about population means. However, they differ in their assumptions and appropriate application scenarios:\n",
    "\n",
    "Z-test:\n",
    "\n",
    "Assumptions:\n",
    "The population standard deviation (σ) is known.\n",
    "The data is normally distributed (or the sample size is large enough for the central limit theorem to apply).\n",
    "Application:\n",
    "When you have a large sample size (n ≥ 30) and know the population standard deviation.\n",
    "Used for hypothesis testing (e.g., comparing a sample mean to a hypothesized population mean) or constructing confidence intervals for the population mean.\n",
    "Example Scenario (Z-test):\n",
    "\n",
    "A bakery wants to estimate the average weight of their bread loaves. They know from historical data that the population standard deviation of loaf weight is 0.2 ounces (σ = 0.2 oz). They take a random sample of 50 loaves and find the sample mean weight to be 16 ounces (x̄ = 16 oz). They want to test the hypothesis that the average loaf weight is exactly 16 ounces (μ = 16 oz) with a significance level of 0.05. Since they know the population standard deviation and have a large sample size, a z-test is appropriate.\n",
    "\n",
    "T-test:\n",
    "\n",
    "Assumptions:\n",
    "The population standard deviation (σ) is unknown.\n",
    "The data is assumed to be normally distributed (although the t-test is more robust to violations of normality for larger sample sizes).\n",
    "Application:\n",
    "When the population standard deviation is unknown and you have a small sample size (typically less than 30).\n",
    "There are two main types of t-tests:\n",
    "One-sample t-test: Compares a sample mean to a hypothesized population mean.\n",
    "Two-sample t-test: Compares the means of two independent samples (can be further divided into tests with equal variances or unequal variances).\n",
    "Example Scenario (T-test):\n",
    "\n",
    "A company is developing a new energy drink and wants to compare its effectiveness in boosting energy levels to a leading competitor's drink. They recruit 20 volunteers (small sample size) and have them try both drinks on separate days. They measure the increase in energy level for each participant. Since the population standard deviation of energy level changes is unknown and the sample size is small, a two-sample t-test would be appropriate to determine if there's a significant difference in the average energy level increase between the two drinks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f1b654-d3d2-4083-84fa-74e5a1dae8e5",
   "metadata": {},
   "source": [
    "2\n",
    "\n",
    "\n",
    "The key difference between one-tailed and two-tailed tests lies in the direction of the alternative hypothesis and how they handle potential deviations from the null hypothesis. Here's a breakdown:\n",
    "\n",
    "One-Tailed Test:\n",
    "\n",
    "Alternative Hypothesis: The alternative hypothesis in a one-tailed test specifies a directional difference from the null hypothesis. It states that the population mean will be either greater than or less than a certain value compared to the null hypothesis which proposes equality.\n",
    "\n",
    "\n",
    "Application: When you have a strong prior expectation about the direction of the effect. For example, you might be testing a new drug that is expected to increase energy levels, or you might be analyzing customer satisfaction data where you suspect scores are generally lower than a certain threshold.\n",
    "\n",
    "\n",
    "Critical Region: Since you're only interested in deviations in one direction, the critical region for the test statistic (e.g., t-statistic or z-statistic) is located only in one tail of the sampling distribution (either left or right tail). This means a smaller p-value is required for significance compared to a two-tailed test.\n",
    "\n",
    "\n",
    "Two-Tailed Test:\n",
    "\n",
    "Alternative Hypothesis: The alternative hypothesis in a two-tailed test is non-directional. It states that the population mean will be different from the null hypothesis, but it doesn't specify a direction (greater than or less than).\n",
    "\n",
    "\n",
    "Application: When you're unsure about the direction of the effect or you want to explore if there's any difference at all compared to the null hypothesis. This is often the case in exploratory research where you're investigating relationships between variables.\n",
    "\n",
    "\n",
    "Critical Region: The critical region for the test statistic is split into two tails of the sampling distribution (one on either side). This means a larger p-value is required for significance compared to a one-tailed test with the same level of confidence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1acea8-b639-4f97-a968-b59932beacbd",
   "metadata": {},
   "source": [
    "3\n",
    "\n",
    "\n",
    "Two common types of errors in hypothesis testing are Type 1 errors and Type 2 errors.\n",
    "\n",
    "Type 1 Error (False Positive):\n",
    "\n",
    "Definition: A Type 1 error occurs when we reject the null hypothesis (H₀) although it's actually true in the population. In simpler terms, we mistakenly conclude that there's a significant difference or effect when there really isn't one.\n",
    "\n",
    "Example Scenario: A pharmaceutical company develops a new drug to treat allergies. They conduct a clinical trial and based on the sample data, they reject the null hypothesis (which states there's no difference between the drug and a placebo) and conclude that the drug is effective. However, in reality, the drug might not be any better than a placebo, and the observed difference in the sample could be due to chance. This would be a Type 1 error.\n",
    "\n",
    "Type 2 Error (False Negative):\n",
    "\n",
    "Definition: A Type 2 error occurs when we fail to reject the null hypothesis (H₀) when it's actually false in the population. In other words, we miss a real difference or effect and incorrectly conclude that there's no significant difference.\n",
    "\n",
    "Example Scenario: A school implements a new teaching method and conducts a statistical analysis to assess its effectiveness on student test scores. The analysis fails to reject the null hypothesis (which states there's no difference between the new method and the old method). This might lead the school to conclude that the new method isn't effective and abandon it. However, the new method might actually be beneficial but the study design or sample size might not have been sufficient to detect a real difference. This would be a Type 2 error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2aacd3-bc70-4646-80ff-464b4f5c6660",
   "metadata": {},
   "source": [
    "4\n",
    "\n",
    "\n",
    "Bayes' theorem is a fundamental concept in probability that allows you to update the probability of an event (hypothesis) based on new evidence. It essentially helps us refine our understanding of a situation by incorporating new information.\n",
    "\n",
    "Here's the formula for Bayes' theorem:\n",
    "\n",
    "P(B|A) = ( P(A|B) * P(B) ) / P(A)\n",
    "\n",
    "Example Scenario:\n",
    "\n",
    "Imagine you have a drawer with two types of socks: black (B) and white (W). You believe there's a 70% chance (P(B) = 0.7) of finding a black sock (prior probability) and a 30% chance (P(W) = 0.3) of finding a white sock. Let's say you reach into the drawer without looking and pull out a sock (event A), and it's black. Now, you want to know the probability that the other sock in the drawer is also black (updated probability of B given the evidence of pulling out a black sock first).\n",
    "\n",
    "Likelihood (P(A|B)): In this case, if the other sock is black (B), the likelihood of randomly pulling out a black sock first (A) is 100% (P(A|B) = 1).\n",
    "Prior Probability (P(B)): We know from before that the prior probability of a black sock (B) is 0.7 (P(B) = 0.7)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a803e927-5aa6-4b7f-877d-62ddfb228a14",
   "metadata": {},
   "source": [
    "5\n",
    "\n",
    "A confidence interval (CI) is a statistical range of values that is estimated to likely contain the true population parameter with a certain level of confidence. It's a way of expressing the precision of your estimate based on sample data.\n",
    "\n",
    "Here's how to calculate a confidence interval and understand its interpretation:\n",
    "\n",
    "1. Point Estimate and Sample Data:\n",
    "\n",
    "You typically start with a point estimate, like a sample mean or proportion, calculated from your sample data. This provides an initial idea of the population parameter you're interested in.\n",
    "You'll also need information about the sample, such as the sample size (n) and the sample standard deviation (s) for continuous data or the number of successes (x) and failures (n-x) for proportions.\n",
    "2. Choosing the Confidence Level:\n",
    "\n",
    "The confidence level (usually denoted by 1 - α) indicates the probability that the constructed interval will capture the true population parameter. Common confidence levels are 90%, 95%, and 99%. A higher confidence level leads to a wider interval.\n",
    "3. Finding the Critical Value:\n",
    "\n",
    "This step depends on the type of data (continuous or proportion) and the chosen confidence level. You can find critical values from z-tables or statistical functions depending on the specific test.\n",
    "4. Confidence Interval Formula:\n",
    "\n",
    "The general formula for a confidence interval (CI) depends on the type of data and the chosen statistic:\n",
    "For continuous data (mean):\n",
    "CI = x̄ ± (z * (s / √n))\n",
    "where: * x̄: Sample mean * z: Critical value from the z-table for the chosen confidence level * s: Sample standard deviation * n: Sample size\n",
    "For proportions: There are different formulas for proportions depending on the specific scenario (one-sample proportion or two-sample proportions), but the concept remains similar.\n",
    "5. Interpretation:\n",
    "\n",
    "The confidence interval represents a range of values. You can be confident (based on the chosen level) that the true population parameter falls within this interval.\n",
    "A wider interval indicates less precision in the estimate, while a narrower interval suggests a more precise estimate based on the sample data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fba113-1b63-4cd6-a8b6-88b28748ff47",
   "metadata": {},
   "source": [
    "6\n",
    "\n",
    "Imagine you are a vet and have a new patient, a dog named Charlie. You suspect Charlie might have a rare ear infection (event B) that only affects 2% of dogs (P(B) = 0.02). This is your prior probability, your initial belief about the likelihood of the infection before any examination.\n",
    "\n",
    "During the examination, you notice some symptoms that are common with this ear infection (event A). Let's say, based on your experience, these symptoms occur in 80% of dogs who actually have the ear infection (P(A|B) = 0.8) but can also appear in 10% of healthy dogs (P(A|not B) = 0.1).\n",
    "\n",
    "We want to calculate the updated probability of Charlie having the ear infection (P(B|A)) after considering the observed symptoms (evidence A).\n",
    "\n",
    "Using Bayes' Theorem:\n",
    "\n",
    "P(B|A) = (P(A|B) * P(B)) / P(A)\n",
    "P(A|B): Likelihood (0.8) - How likely are the symptoms (A) given the dog has the infection (B)?\n",
    "P(B): Prior probability (0.02) - Initial belief of the infection prevalence before examining Charlie.\n",
    "P(A): Total probability of the symptoms occurring (regardless of the infection). We need to calculate this term to find the posterior probability.\n",
    "Calculating P(A):\n",
    "\n",
    "P(A) represents the probability of observing the symptoms (A), which can happen in two ways:\n",
    "\n",
    "The dog has the infection (B) and exhibits the symptoms (A).\n",
    "The dog doesn't have the infection (not B) but still shows the symptoms (A).\n",
    "Therefore, P(A) can be calculated as follows:\n",
    "\n",
    "P(A) = (P(A|B) * P(B)) + (P(A|not B) * P(not B))\n",
    "P(A|not B): How likely are the symptoms (A) given the dog does NOT have the infection (not B)? (0.1 in this case)\n",
    "P(not B): Probability of the dog NOT having the infection (1 - P(B)) = (1 - 0.02) = 0.98\n",
    "Plugging in the values:\n",
    "\n",
    "P(A) = (0.8 * 0.02) + (0.1 * 0.98)\n",
    "     = 0.016 + 0.098\n",
    "     = 0.114\n",
    "Now we can find the posterior probability (P(B|A)):\n",
    "\n",
    "P(B|A) = (0.8 * 0.02) / 0.114\n",
    "       = 0.016 / 0.114\n",
    "       ≈ 0.14\n",
    "Interpretation:\n",
    "\n",
    "Before examining Charlie, you believed there was a 2% chance (prior probability) of him having the ear infection. After considering the symptoms (evidence A), the updated probability (posterior probability) of Charlie having the ear infection increases to approximately 14%. While the symptoms make the infection more likely, it's still a relatively uncommon condition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6eabf4d-5e0a-413e-88a1-93ddcecc31c8",
   "metadata": {},
   "source": [
    "7\n",
    "\n",
    "So, the 95% confidence interval would be approximately \n",
    "(49.02,50.98). if we take n as 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13853ac-5f45-4e8c-a4a3-e00a43c1b5dc",
   "metadata": {},
   "source": [
    "8\n",
    "The margin of error in a confidence interval represents the range within which we expect the true population parameter (such as the population mean) to lie. It is calculated by multiplying the standard error (the standard deviation of the sampling distribution) by the critical value corresponding to the desired level of confidence.\n",
    "\n",
    "\n",
    "Margin of Error=Critical Value×Standard Error\n",
    "\n",
    "\n",
    "Consider a scenario where you want to estimate the average height of students in a university. You take two samples, one with 50 students and another with 200 students.\n",
    "\n",
    "For the sample with 50 students:\n",
    "\n",
    "Suppose the margin of error is 1 inch.\n",
    "This suggests that with 95% confidence, the true average height of the student population lies within 1 inch of the sample mean.\n",
    "For the sample with 200 students:\n",
    "\n",
    "With the same level of confidence, the margin of error might decrease to, say, 0.5 inches.\n",
    "This implies that the estimate of the true average height is more precise with the larger sample size, as the range within which the true population mean is likely to fall has been reduced.\n",
    "In summary, larger sample sizes lead to smaller margins of error, indicating a more precise estimate of the population parameter.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df88e285-2e2f-43cd-9fa8-1f48b81be6a6",
   "metadata": {},
   "source": [
    "9\n",
    "\n",
    "Calculating the z-score:\n",
    "\n",
    "The z-score formula is:\n",
    "\n",
    "z = (x - μ) / σ\n",
    "where:\n",
    "\n",
    "x = data point value (75)\n",
    "μ = population mean (70)\n",
    "σ = population standard deviation (5)\n",
    "Plugging in the values:\n",
    "\n",
    "z = (75 - 70) / 5\n",
    "   = 5 / 5\n",
    "   = 1.00\n",
    "Interpretation:\n",
    "\n",
    "The z-score of 1.00 indicates that the data point (75) is 1.00 standard deviation above the population mean (70). In other words, this data point is higher than the average by one standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47af829-c7b8-42f3-85fc-d593a658c766",
   "metadata": {},
   "source": [
    "10\n",
    "\n",
    "Here's how to conduct a hypothesis test to determine the effectiveness of the weight loss drug using a one-sample t-test at a 95% confidence level:\n",
    "\n",
    "1. Null Hypothesis (H₀) and Alternative Hypothesis (H₁):\n",
    "\n",
    "H₀: The average weight loss with the drug is not significantly different from 0 pounds. (There's no effect)\n",
    "H₁: The average weight loss with the drug is greater than 0 pounds. (There's a positive effect)\n",
    "2. Significance Level (α):\n",
    "\n",
    "α = 0.05 (This is a 95% confidence level; 1 - α = 0.95)\n",
    "\n",
    "3. Test Statistic (t-statistic):\n",
    "\n",
    "Since we don't know the population standard deviation (σ) and have a relatively small sample size (n = 50), a one-sample t-test is appropriate.\n",
    "\n",
    "t = (x̄ - μ₀) / (s / √n)\n",
    "                                                                     \n",
    "This critical value can be found using statistical tables or software. For a one-tailed test at a 95% confidence level and 49 degrees of freedom, the critical t-value is approximately 1.676.                                                                   \n",
    "t statistic value is 16.97   \n",
    "Since the calculated t-statistic (16.97) is greater than the critical t-value (1.676), we reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0215ff16-9b6a-41d7-974b-054b04a9a880",
   "metadata": {},
   "source": [
    "11\n",
    "\n",
    "Confidence Interval=0.65±1.96×0.0213\n",
    "\n",
    "Confidence Interval=0.65±0.0418\n",
    "\n",
    "So, the 95% confidence interval for the true proportion of people who are satisfied with their job is approximately \n",
    "(0.6082,0.6918).\n",
    "\n",
    "Interpretation:\n",
    "We are 95% confident that the true proportion of people who are satisfied with their job lies between 60.82% and 69.18%. In other words, if we were to repeat this survey many times and calculate confidence intervals in the same manner, approximately 95% of those intervals would contain the true proportion of people who are satisfied with their job."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045672cd-375d-4faa-9d0a-ecbd6882bef0",
   "metadata": {},
   "source": [
    "12\n",
    "\n",
    "1. Null Hypothesis (H₀) and Alternative Hypothesis (H₁):\n",
    "\n",
    "H₀: There is no significant difference in the mean scores between students taught with Method A and Method B (μ₁ - μ₂ = 0).\n",
    "H₁: There is a significant difference in the mean scores between the two methods (μ₁ ≠ μ₂).\n",
    "\n",
    "2. Significance Level (α):\n",
    "\n",
    "α = 0.01 (This is a 1% significance level)\n",
    "\n",
    "3. Assumptions for the t-test:\n",
    "\n",
    "Both samples are independent random samples from their respective populations.\n",
    "The data for both groups is normally distributed (or close to normal).\n",
    "The variances of the two populations are equal (homoscedasticity).\n",
    "4. Checking Assumptions:\n",
    "\n",
    "Normality of data distribution can be assessed visually with histograms or Q-Q plots, or with normality tests like Shapiro-Wilk (although these might not be very powerful with small samples). Homoscedasticity can be checked with Levene's test. Depending on the results of these tests, you might need to consider alternative approaches if the assumptions are not met (e.g., Welch's t-test for unequal variances).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52de154-6ffa-490e-b3e0-efda2ed0c2c7",
   "metadata": {},
   "source": [
    "13\n",
    "\n",
    "To calculate the 90% confidence interval for the true population mean, \n",
    "we'll use the formula for a confidence interval:\n",
    "\n",
    "\n",
    "x̄ ± (z* * σ / √n)\n",
    "\n",
    "Now, let's calculate the confidence interval:\n",
    "\n",
    "Confidence Interval=65±1.645×1.132\n",
    "Confidence Interval=65±1.859\n",
    "\n",
    "So, the 90% confidence interval for the true population mean is approximately \n",
    "\n",
    "(63.141,66.859).\n",
    "\n",
    "Interpretation:\n",
    "We are 90% confident that the true population mean lies within the range of 63.141 and 66.859. In other words, if we were to repeat this process for many samples and calculate confidence intervals in the same manner, approximately 90% of those intervals would contain the true population mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3323167-e023-417d-9e4c-76692526d175",
   "metadata": {},
   "source": [
    "14\n",
    "\n",
    "1. Null Hypothesis (H₀) and Alternative Hypothesis (H₁):\n",
    "\n",
    "H₀: Caffeine has no significant effect on reaction time. The average reaction time with caffeine (μ) is equal to a hypothesized value (often set to 0 for convenience). Let's set μ₀ = 0.\n",
    "H₁: Caffeine has a significant effect on reaction time. The average reaction time with caffeine (μ) is not equal to 0 seconds. (We aren't specifying the direction of the effect yet)\n",
    "2. Significance Level (α):\n",
    "\n",
    "α = 0.10 (This is a 10% significance level for a 90% confidence level)\n",
    "\n",
    "3. Test Statistic (t-statistic):\n",
    "\n",
    "Since we don't know the population standard deviation (σ) and have a relatively small sample size (n = 30), a one-sample t-test is appropriate.\n",
    "\n",
    "t = (x̄ - μ₀) / (s / √n)\n",
    "where:\n",
    "\n",
    "x̄ = Sample mean reaction time (0.25 seconds)\n",
    "μ₀ = Hypothesized mean under H₀ (0 seconds)\n",
    "s = Sample standard deviation (0.05 seconds)\n",
    "n = Sample size (30)\n",
    "\n",
    "                                                                                                                                \n",
    "4. Critical Value:\n",
    "\n",
    "We need to find the critical t-value for a one-tailed test with α = 0.10 and degrees of freedom (df) = n - 1 = 29. You can use a t-table or statistical software to find this value. In this case, for a one-tailed test at α = 0.10 and df = 29, the critical t-value (t*) is approximately 1.310.\n",
    "\n",
    "5. Decision Rule:\n",
    "\n",
    "Reject H₀ if the calculated t-statistic (15) is greater than the critical t-value (1.310).\n",
    "Fail to reject H₀ if the calculated t-statistic is less than or equal to the critical t-value.\n",
    "6. Conclusion:\n",
    "\n",
    "Since the calculated t-statistic (15) is much larger than the critical t-value (1.310), we reject the null hypothesis (H₀) at a 10% significance level. This suggests that the average reaction time of 0.25 seconds is statistically significant and provides evidence that caffeine has an effect on reaction time at a level different from 0 seconds on average in this sample.\n",
    "                                                                                                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b89e923-61ea-48da-b2a7-b2416d96306a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
